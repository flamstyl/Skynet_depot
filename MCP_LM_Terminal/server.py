"""
üü£ MCP_LM_Terminal - Serveur FastAPI Principal
Serveur MCP local pour interfacer ChatGPT/Claude avec LM Studio + Terminal IA

Fonctionnalit√©s :
- Routes MCP pour status, requ√™tes LM Studio, commandes terminal
- WebSocket optionnel pour terminal interactif
- Authentification via token API
- Interface avec LM Studio local
"""

import json
import logging
from pathlib import Path
from typing import Optional, Dict, Any

from fastapi import FastAPI, HTTPException, Header, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

from terminal_handler import TerminalHandler
from lmstudio_client import LMStudioClient

# ============= CONFIGURATION =============

# Chargement de la configuration
CONFIG_PATH = Path(__file__).parent / "config.json"

def load_config() -> Dict[str, Any]:
    """Charge la configuration depuis config.json"""
    if not CONFIG_PATH.exists():
        raise FileNotFoundError(f"Fichier config.json introuvable : {CONFIG_PATH}")

    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

config = load_config()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============= INITIALISATION =============

app = FastAPI(
    title="MCP LM Terminal Server",
    description="Serveur MCP local pour LM Studio + Terminal IA",
    version="1.0.0"
)

# Configuration CORS (pour acc√®s depuis ChatGPT/Claude)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # √Ä restreindre en production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialisation des handlers
terminal_handler = TerminalHandler(timeout=config["terminal"]["timeout"])
lm_client = LMStudioClient(config["lmstudio"])

# ============= MOD√àLES PYDANTIC =============

class LMQueryRequest(BaseModel):
    """Requ√™te pour interroger LM Studio"""
    prompt: str = Field(..., description="Prompt √† envoyer au mod√®le LM")
    temperature: float = Field(0.7, ge=0.0, le=2.0, description="Temp√©rature de g√©n√©ration")
    max_tokens: int = Field(512, ge=1, le=4096, description="Nombre maximum de tokens")
    model: Optional[str] = Field(None, description="Mod√®le sp√©cifique (optionnel)")

class TerminalCommandRequest(BaseModel):
    """Requ√™te pour ex√©cuter une commande terminal"""
    cmd: str = Field(..., description="Commande shell √† ex√©cuter")
    timeout: Optional[int] = Field(None, description="Timeout personnalis√© en secondes")

class StatusResponse(BaseModel):
    """R√©ponse de status du serveur"""
    status: str
    lm_studio: Dict[str, Any]
    terminal: Dict[str, str]
    version: str

# ============= MIDDLEWARES =============

def verify_token(authorization: Optional[str] = Header(None)) -> bool:
    """
    V√©rifie le token d'authentification
    Format attendu : Bearer <token>
    """
    expected_token = config["api_token"]

    if not authorization:
        raise HTTPException(status_code=401, detail="Token d'authentification manquant")

    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Format de token invalide (attendu: Bearer <token>)")

    token = authorization.replace("Bearer ", "")

    if token != expected_token:
        raise HTTPException(status_code=403, detail="Token d'authentification invalide")

    return True

# ============= ROUTES API =============

@app.get("/")
async def root():
    """Route racine - Info serveur"""
    return {
        "name": "MCP LM Terminal Server",
        "version": "1.0.0",
        "status": "online",
        "endpoints": {
            "status": "/status",
            "lm_query": "/lm/query",
            "terminal": "/terminal/cmd",
            "websocket": "/terminal/stream"
        }
    }

@app.get("/status", response_model=StatusResponse)
async def get_status(authorized: bool = Header(None, alias="authorization", convert_underscores=True)):
    """
    üîπ GET /status
    Retourne l'√©tat complet du serveur MCP

    Authentification requise via Header : Authorization: Bearer <token>
    """
    verify_token(authorized)

    # V√©rification LM Studio
    lm_status = await lm_client.check_status()

    return StatusResponse(
        status="online",
        lm_studio={
            "connected": lm_status["connected"],
            "host": config["lmstudio"]["host"],
            "model": config["lmstudio"]["model"],
            "available": lm_status["available"]
        },
        terminal={
            "status": "online",
            "timeout": f"{config['terminal']['timeout']}s"
        },
        version="1.0.0"
    )

@app.post("/lm/query")
async def lm_query(
    request: LMQueryRequest,
    authorization: Optional[str] = Header(None)
):
    """
    üîπ POST /lm/query
    Transmet une requ√™te √† LM Studio et retourne la r√©ponse

    Body JSON:
    {
        "prompt": "Votre question",
        "temperature": 0.7,
        "max_tokens": 512,
        "model": "default" (optionnel)
    }

    Authentification requise via Header : Authorization: Bearer <token>
    """
    verify_token(authorization)

    try:
        logger.info(f"Requ√™te LM Studio : {request.prompt[:50]}...")

        # Transmission √† LM Studio
        response = await lm_client.completion(
            prompt=request.prompt,
            temperature=request.temperature,
            max_tokens=request.max_tokens,
            model=request.model
        )

        return {
            "success": True,
            "response": response,
            "model": request.model or config["lmstudio"]["model"],
            "tokens": request.max_tokens
        }

    except Exception as e:
        logger.error(f"Erreur LM Studio : {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur LM Studio : {str(e)}")

@app.post("/terminal/cmd")
async def terminal_command(
    request: TerminalCommandRequest,
    authorization: Optional[str] = Header(None)
):
    """
    üîπ POST /terminal/cmd
    Ex√©cute une commande shell et retourne le r√©sultat

    Body JSON:
    {
        "cmd": "ls -la",
        "timeout": 20 (optionnel)
    }

    Authentification requise via Header : Authorization: Bearer <token>
    """
    verify_token(authorization)

    try:
        logger.info(f"Ex√©cution commande : {request.cmd}")

        # Ex√©cution de la commande
        result = terminal_handler.execute_command(
            request.cmd,
            timeout=request.timeout
        )

        return {
            "success": True,
            "command": request.cmd,
            "stdout": result["stdout"],
            "stderr": result["stderr"],
            "exit_code": result["exit_code"],
            "execution_time": result.get("execution_time", 0)
        }

    except Exception as e:
        logger.error(f"Erreur terminal : {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur terminal : {str(e)}")

@app.websocket("/terminal/stream")
async def terminal_websocket(websocket: WebSocket):
    """
    üîπ WebSocket /terminal/stream
    Terminal interactif bi-directionnel (optionnel mais recommand√©)

    Permet une interaction continue type SSH avec le terminal local
    """
    await websocket.accept()
    logger.info("WebSocket terminal connect√©")

    try:
        # Cr√©ation d'une session terminal PTY
        pty_session = terminal_handler.create_pty_session()

        # Envoi du message de bienvenue
        await websocket.send_json({
            "type": "connected",
            "message": "Terminal interactif MCP - Session active"
        })

        while True:
            # R√©ception des commandes du client
            data = await websocket.receive_text()

            if data.strip().lower() in ["exit", "quit", "bye"]:
                await websocket.send_json({
                    "type": "info",
                    "message": "Fermeture de la session terminal"
                })
                break

            # Ex√©cution de la commande via PTY
            output = pty_session.execute(data)

            # Envoi du r√©sultat
            await websocket.send_json({
                "type": "output",
                "command": data,
                "result": output
            })

    except WebSocketDisconnect:
        logger.info("WebSocket terminal d√©connect√©")

    except Exception as e:
        logger.error(f"Erreur WebSocket : {str(e)}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": str(e)
            })
        except:
            pass

    finally:
        # Nettoyage de la session PTY
        if 'pty_session' in locals():
            pty_session.close()

# ============= √âV√âNEMENTS LIFECYCLE =============

@app.on_event("startup")
async def startup_event():
    """√âv√©nement au d√©marrage du serveur"""
    logger.info("üü£ MCP LM Terminal Server - D√©marrage...")
    logger.info(f"üì° LM Studio : {config['lmstudio']['host']}")
    logger.info(f"üñ•Ô∏è  Terminal : Timeout {config['terminal']['timeout']}s")
    logger.info(f"üîí Auth : Token configur√©")

    # Test de connexion LM Studio
    lm_status = await lm_client.check_status()
    if lm_status["connected"]:
        logger.info("‚úÖ LM Studio : Connexion r√©ussie")
    else:
        logger.warning("‚ö†Ô∏è  LM Studio : Non disponible (v√©rifiez que LM Studio est lanc√©)")

@app.on_event("shutdown")
async def shutdown_event():
    """√âv√©nement √† l'arr√™t du serveur"""
    logger.info("üõë MCP LM Terminal Server - Arr√™t...")
    terminal_handler.cleanup()

# ============= POINT D'ENTR√âE =============

if __name__ == "__main__":
    # Lancement du serveur
    host = config["server"]["host"]
    port = config["server"]["port"]

    logger.info(f"üöÄ D√©marrage sur {host}:{port}")

    uvicorn.run(
        "server:app",
        host=host,
        port=port,
        reload=False,
        log_level="info"
    )
