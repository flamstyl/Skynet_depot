# Grok CLI Configuration
version: "2.0.0"

# General Settings
general:
  project_scan_depth: 5
  max_file_size_mb: 10
  excluded_dirs:
    - node_modules
    - .git
    - __pycache__
    - venv
    - .venv
    - dist
    - build
  excluded_extensions:
    - .pyc
    - .log
    - .tmp

# Execution Settings
execution:
  default_shell: bash
  command_timeout: 300  # seconds
  max_concurrent_commands: 3
  sandbox_mode: true
  docker_enabled: true

# Memory System
memory:
  short_term_size: 50  # last N operations
  long_term_enabled: true
  vector_store_path: ./data/vectorstore
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  chunk_size: 512
  chunk_overlap: 50

# RAG Configuration
rag:
  enabled: true
  top_k_results: 5
  similarity_threshold: 0.7
  index_on_startup: true
  auto_update: true

# Docker Sandbox
docker:
  image: grok-cli-sandbox:latest
  network: bridge
  memory_limit: 2g
  cpu_limit: 2
  security:
    read_only_root: false
    no_new_privileges: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

# MCP Server
mcp:
  enabled: true
  host: localhost
  port: 3100
  tools:
    - analyze_project
    - execute_command
    - generate_code
    - run_tests
    - search_memory
    - get_diagnostics

# API Server
api:
  enabled: true
  host: 0.0.0.0
  port: 8100
  cors_origins:
    - http://localhost:3000
    - http://localhost:5173
  auth_enabled: false

# Dashboard
dashboard:
  enabled: true
  host: localhost
  port: 8501
  update_interval: 2  # seconds
  max_log_lines: 1000

# LLM Configuration
llm:
  provider: openai  # or anthropic, ollama, etc.
  model: gpt-4
  temperature: 0.3
  max_tokens: 4000
  api_key_env: OPENAI_API_KEY

# Logging
logging:
  level: INFO
  file: ./logs/grok_cli.log
  max_size_mb: 100
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
