{
  "name": "local-llm-mcp",
  "version": "1.0.0",
  "description": "MCP Server pour LLM locaux",
  "capabilities": {
    "tools": true,
    "resources": false,
    "prompts": true
  },
  "transport": {
    "type": "stdio",
    "command": "node",
    "args": ["dist/server.js"]
  },
  "backends": {
    "ollama": {
      "url": "http://localhost:11434",
      "enabled": true
    },
    "lmstudio": {
      "url": "http://localhost:1234",
      "enabled": true
    },
    "qwen": {
      "url": "http://localhost:8000",
      "enabled": false
    },
    "gpt4all": {
      "url": "http://localhost:4891",
      "enabled": false
    }
  }
}
