# Local LLM MCP Configuration

# Server
MCP_PORT=3200
NODE_ENV=development
LOG_LEVEL=info

# Backends
OLLAMA_URL=http://localhost:11434
LMSTUDIO_URL=http://localhost:1234
QWEN_URL=http://localhost:8000
GPT4ALL_URL=http://localhost:4891

# Default Backend
DEFAULT_BACKEND=ollama

# Limits
MAX_PROMPT_SIZE=50000
MAX_TOKENS=4096
DEFAULT_TEMPERATURE=0.7
REQUEST_TIMEOUT=120000
